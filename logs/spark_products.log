:: loading settings :: url = jar:file:/opt/bitnami/spark/jars/ivy-2.5.0.jar!/org/apache/ivy/core/settings/ivysettings.xml
Ivy Default Cache set to: /opt/bitnami/spark/.ivy2/cache
The jars for the packages stored in: /opt/bitnami/spark/.ivy2/jars
org.apache.spark#spark-sql-kafka-0-10_2.12 added as a dependency
org.postgresql#postgresql added as a dependency
:: resolving dependencies :: org.apache.spark#spark-submit-parent-2abe1a5e-660a-46ff-a2e5-0323f7dd4238;1.0
	confs: [default]
	found org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.2 in central
	found org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.2 in central
	found org.apache.kafka#kafka-clients;2.6.0 in central
	found com.github.luben#zstd-jni;1.4.8-1 in central
	found org.lz4#lz4-java;1.7.1 in central
	found org.xerial.snappy#snappy-java;1.1.8.2 in central
	found org.slf4j#slf4j-api;1.7.30 in central
	found org.spark-project.spark#unused;1.0.0 in central
	found org.apache.commons#commons-pool2;2.6.2 in central
	found org.postgresql#postgresql;42.3.1 in central
	found org.checkerframework#checker-qual;3.5.0 in central
downloading https://repo1.maven.org/maven2/org/apache/spark/spark-sql-kafka-0-10_2.12/3.1.2/spark-sql-kafka-0-10_2.12-3.1.2.jar ...
	[SUCCESSFUL ] org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.2!spark-sql-kafka-0-10_2.12.jar (199ms)
downloading https://repo1.maven.org/maven2/org/postgresql/postgresql/42.3.1/postgresql-42.3.1.jar ...
	[SUCCESSFUL ] org.postgresql#postgresql;42.3.1!postgresql.jar (431ms)
downloading https://repo1.maven.org/maven2/org/apache/spark/spark-token-provider-kafka-0-10_2.12/3.1.2/spark-token-provider-kafka-0-10_2.12-3.1.2.jar ...
	[SUCCESSFUL ] org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.2!spark-token-provider-kafka-0-10_2.12.jar (99ms)
downloading https://repo1.maven.org/maven2/org/apache/kafka/kafka-clients/2.6.0/kafka-clients-2.6.0.jar ...
	[SUCCESSFUL ] org.apache.kafka#kafka-clients;2.6.0!kafka-clients.jar (1967ms)
downloading https://repo1.maven.org/maven2/org/apache/commons/commons-pool2/2.6.2/commons-pool2-2.6.2.jar ...
	[SUCCESSFUL ] org.apache.commons#commons-pool2;2.6.2!commons-pool2.jar (156ms)
downloading https://repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar ...
	[SUCCESSFUL ] org.spark-project.spark#unused;1.0.0!unused.jar (83ms)
downloading https://repo1.maven.org/maven2/com/github/luben/zstd-jni/1.4.8-1/zstd-jni-1.4.8-1.jar ...
	[SUCCESSFUL ] com.github.luben#zstd-jni;1.4.8-1!zstd-jni.jar (3370ms)
downloading https://repo1.maven.org/maven2/org/lz4/lz4-java/1.7.1/lz4-java-1.7.1.jar ...
	[SUCCESSFUL ] org.lz4#lz4-java;1.7.1!lz4-java.jar (368ms)
downloading https://repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.8.2/snappy-java-1.1.8.2.jar ...
	[SUCCESSFUL ] org.xerial.snappy#snappy-java;1.1.8.2!snappy-java.jar(bundle) (1063ms)
downloading https://repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.30/slf4j-api-1.7.30.jar ...
	[SUCCESSFUL ] org.slf4j#slf4j-api;1.7.30!slf4j-api.jar (103ms)
downloading https://repo1.maven.org/maven2/org/checkerframework/checker-qual/3.5.0/checker-qual-3.5.0.jar ...
	[SUCCESSFUL ] org.checkerframework#checker-qual;3.5.0!checker-qual.jar (225ms)
:: resolution report :: resolve 5919ms :: artifacts dl 8085ms
	:: modules in use:
	com.github.luben#zstd-jni;1.4.8-1 from central in [default]
	org.apache.commons#commons-pool2;2.6.2 from central in [default]
	org.apache.kafka#kafka-clients;2.6.0 from central in [default]
	org.apache.spark#spark-sql-kafka-0-10_2.12;3.1.2 from central in [default]
	org.apache.spark#spark-token-provider-kafka-0-10_2.12;3.1.2 from central in [default]
	org.checkerframework#checker-qual;3.5.0 from central in [default]
	org.lz4#lz4-java;1.7.1 from central in [default]
	org.postgresql#postgresql;42.3.1 from central in [default]
	org.slf4j#slf4j-api;1.7.30 from central in [default]
	org.spark-project.spark#unused;1.0.0 from central in [default]
	org.xerial.snappy#snappy-java;1.1.8.2 from central in [default]
	---------------------------------------------------------------------
	|                  |            modules            ||   artifacts   |
	|       conf       | number| search|dwnlded|evicted|| number|dwnlded|
	---------------------------------------------------------------------
	|      default     |   11  |   11  |   11  |   0   ||   11  |   11  |
	---------------------------------------------------------------------
:: retrieving :: org.apache.spark#spark-submit-parent-2abe1a5e-660a-46ff-a2e5-0323f7dd4238
	confs: [default]
	11 artifacts copied, 0 already retrieved (14284kB/112ms)
25/05/20 12:05:31 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
25/05/20 12:05:47 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-03dd8823-c8d6-4b78-af63-a0e7a139b6a8. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.
25/05/20 12:05:47 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.
[Stage 0:>                                                          (0 + 1) / 1]                                                                                [Stage 3:>                                                          (0 + 1) / 1]                                                                                25/05/20 12:57:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-d1a5829c-59b2-4dfb-bda5-d9b52990e79c-658359547-driver-0-1, groupId=spark-kafka-source-d1a5829c-59b2-4dfb-bda5-d9b52990e79c-658359547-driver-0] Connection to node 1001 (kafka/172.20.0.6:9092) could not be established. Broker may not be available.
25/05/20 12:57:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-d1a5829c-59b2-4dfb-bda5-d9b52990e79c-658359547-driver-0-1, groupId=spark-kafka-source-d1a5829c-59b2-4dfb-bda5-d9b52990e79c-658359547-driver-0] Connection to node 1001 (kafka/172.20.0.6:9092) could not be established. Broker may not be available.
25/05/20 12:57:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-d1a5829c-59b2-4dfb-bda5-d9b52990e79c-658359547-driver-0-1, groupId=spark-kafka-source-d1a5829c-59b2-4dfb-bda5-d9b52990e79c-658359547-driver-0] Connection to node 1001 (kafka/172.20.0.6:9092) could not be established. Broker may not be available.
25/05/20 12:57:57 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-d1a5829c-59b2-4dfb-bda5-d9b52990e79c-658359547-driver-0-1, groupId=spark-kafka-source-d1a5829c-59b2-4dfb-bda5-d9b52990e79c-658359547-driver-0] Connection to node 1001 (kafka/172.20.0.6:9092) could not be established. Broker may not be available.
25/05/20 12:57:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-d1a5829c-59b2-4dfb-bda5-d9b52990e79c-658359547-driver-0-1, groupId=spark-kafka-source-d1a5829c-59b2-4dfb-bda5-d9b52990e79c-658359547-driver-0] Connection to node 1001 (kafka/172.20.0.6:9092) could not be established. Broker may not be available.
25/05/20 12:57:58 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-d1a5829c-59b2-4dfb-bda5-d9b52990e79c-658359547-driver-0-1, groupId=spark-kafka-source-d1a5829c-59b2-4dfb-bda5-d9b52990e79c-658359547-driver-0] Connection to node 2147482646 (kafka/172.20.0.6:9092) could not be established. Broker may not be available.
25/05/20 12:58:00 WARN NetworkClient: [Consumer clientId=consumer-spark-kafka-source-d1a5829c-59b2-4dfb-bda5-d9b52990e79c-658359547-driver-0-1, groupId=spark-kafka-source-d1a5829c-59b2-4dfb-bda5-d9b52990e79c-658359547-driver-0] Connection to node 1001 (kafka/172.20.0.6:9092) could not be established. Broker may not be available.
25/05/20 12:58:07 ERROR TaskSchedulerImpl: Lost executor 0 on 172.20.0.7: Remote RPC client disassociated. Likely due to containers exceeding thresholds, or network issues. Check driver logs for WARN messages.
